<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Why is Deep Learning Important</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/clean-blog.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="index.html">Deep Learning</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="index.html">BLOG Home</a>
                    </li>
                    <li>
                        <a href="about.html">About</a>
                    </li>
                    <li>
                        <a href="../index.html">MAIN PAGE</a>
                    </li>
                    <li>
                        <a href="contact.html">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('img/post-bg.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1> Why is Deep Learning Important</h1>
                        <h2 class="subheading">Works like a human brain : Research Happens in Leading Tech Companies </h2>
                        <span class="meta">Posted by <a href="#">Srivignessh Pss</a> on June 21, 2015</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <nav>
            		<ul class="pager">
              		<li><a href="1.html">Previous</a></li>
              		<li><a href="3.html">Next</a></li>
            		</ul>
          			</nav>
                    <p>Deep Learning learns the solutions to problems in a way human brain learns hence could solve any problems </p>
                    <p><h4>FACEBOOK AI LAB</h4></p>

                    <p><a href="http://fortune.com/2015/06/15/facebook-ai-moments/"><h5> Moments </h5></a></p>
					<p>Facebook launched its Moments product, which uses Facebook’s image recognition abilities to scan your photos for your friends and then lets people create private photo albums with a particular group, such as the people in the photo. The idea is to make it easier to share photos from a big event among attendees without the cumbersome process of emailing snapshots to everyone or the awkward end-of-event huddle while six people take the exact same group shot. It’s not a cure for cancer, but behind the scenes of this new feature is an impressive technology that Facebook has been working on for years.</p>

					<p>A key element of the Moments feature is the ability for Facebook’s algorithms to recognize people’s faces across different photos, so that Moments knows who was at the event..</p>
					

					<p><h4>GOOGLE BRAIN, DEEPMIND, DNNRESEARCH</h4> </p>
                   
					<p><a href="http://googleresearch.blogspot.in/2015/06/inceptionism-going-deeper-into-neural.html"><h5> Inceptionism: Going Deeper into Neural Networks </h5></a></p>
					<p>Artificial Neural Networks have spurred remarkable recent progress in image classification and speech recognition. But even though these are very useful tools based on well-known mathematical methods, we actually understand surprisingly little of why certain models work and others don’t. So let’s take a look at some simple techniques for peeking inside these networks.</p>

					<p>We train an artificial neural network by showing it millions of training examples and gradually adjusting the network parameters until it gives the classifications we want. The network typically consists of 10-30 stacked layers of artificial neurons. Each image is fed into the input layer, which then talks to the next layer, until eventually the “output” layer is reached. The network’s “answer” comes from this final output layer.</p>

					<p>One of the challenges of neural networks is understanding what exactly goes on at each layer. We know that after training, each layer progressively extracts higher and higher-level features of the image, until the final layer essentially makes a decision on what the image shows. For example, the first layer maybe looks for edges or corners. Intermediate layers interpret the basic features to look for overall shapes or components, like a door or a leaf. The final few layers assemble those into complete interpretations—these neurons activate in response to very complex things such as entire buildings or trees.</p>

					<p>One way to visualize what goes on is to turn the network upside down and ask it to enhance an input image in such a way as to elicit a particular interpretation. Say you want to know what sort of image would result in “Banana.” Start with an image full of random noise, then gradually tweak the image towards what the neural net considers a banana By itself, that doesn’t work very well, but it does if we impose a prior constraint that the image should have similar statistics to natural images, such as neighboring pixels needing to be correlated.
					</p>
					<div class="embed-responsive embed-responsive-4by3">
					  <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/xN1d3qHMIEQ"></iframe>
					</div>
					
                    <p><h4>IBM WATSON RESEARCH</h4> </p>
                   
					<p><a href="http://venturebeat.com/2015/03/04/ibm-acquires-alchemyapi-to-bring-deep-learning-to-watson/"><h5> IBM acquires AlchemyAPI to bring deep learning to Watson </h5></a></p>
					<p>AlchemyAPI’s capabilities in the world of natural language processing include entity extraction, sentiment analysis, and language extraction. When it comes to computer vision, it can tag images and detect faces. The startup charges based on how many transactions are conducted through its application programming interface (API).</p>

					<p><h4>MICROSOFT RESEARCH</h4> </p>
                   
					<p><a href="http://research.microsoft.com/en-us/news/features/dnnvision-071414.aspx"><h5> Project Adam</h5></a></p>
					<p>Project Adam, an initiative by Microsoft researchers and engineers, aims to demonstrate that large-scale, commodity distributed systems can train huge deep neural networks effectively. For proof, the researchers created the world’s best photograph classifier, using 14 million images from ImageNet, an image database divided into 22,000 categories.</p>

					<p>Included in the vast array of categories are some that pertain to dogs. Project Adam knows dogs. It can identify dogs in images. It can identify kinds of dogs. It can even identify particular breeds, such as whether a corgi is a Pembroke or a Cardigan.</p>

					<p>Now, if this all sounds vaguely familiar, that’s because it is—vaguely. A couple of years ago, The New York Times wrote a story about Google using a network of 16,000 computers to teach itself to identify images of cats. That is a difficult task for computers, and it was an impressive achievement.</p>

					<p>Project Adam is 50 times faster—and more than twice as accurate, as outlined in a paper currently under academic review. In addition, it is efficient, using 30 times fewer machines, and scalable, areas in which the Google effort fell short.</p>
					<div class="embed-responsive embed-responsive-4by3">
					  <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/S4ZgfYoeyCo"></iframe>
					</div>
					

					<p><h4>YAHOO RESEARCH</h4> </p>
                    <p><a href="http://techcrunch.com/2013/10/23/yahoo-acquires-startup-lookflow-to-work-on-flickr-and-deep-learning/"><h5> Yahoo Acquires Startup LookFlow To Work On Flickr And ‘Deep Learning'</h5></a></p>
					<p>LookFlow, a startup that describes itself as “an entirely new way to explore images you love,” just announced that it has been acquired by Yahoo and will be joining the Flickr team.</p>

					<p>The company writes on its homepage, “Fret not, LookFlow fans. Keep an eye out for our product in future versions of Flickr — with many more wonderful photos and all that Flickr awesomeness!” It also says it will be helping Yahoo to form a new “deep learning group.”</p>

					<p>When I emailed Yahoo for confirmation, a company spokesperson told me, “We have acquired LookFlow, an enhanced image recognition company,” and they pointed me to the aforementioned LookFlow homepage..</p>

					<p><h4>BAIDU RESEARCH</h4> </p>
                    <p><a href="https://gigaom.com/2015/01/14/baidu-has-built-a-supercomputer-for-deep-learning/"><h5> Baidu built a supercomputer for deep learning </h5></a></p>
					<p>Chinese search engine company Baidu says it has built the world’s most-accurate computer vision system, dubbed Deep Image, which runs on a supercomputer optimized for deep learning algorithms. Baidu claims a 5.98 percent error rate on the ImageNet object classification benchmark; a team from Google won the 2014 ImageNet competition with a 6.66 percent error rate.</p>

					<p> In experiments, humans achieved an estimated error rate of 5.1 percent on the ImageNet dataset.</p>

					<p>The star of Deep Image is almost certainly the supercomputer, called Minwa, which Baidu built to house the system. Deep learning researchers have long (well, for the past few years) used GPUs in order to handle the computational intensity of training their models. In fact, the Deep Image research paper cites a study showing that 12 GPUs in a 3-machine cluster can rival the performance of the performance of the 1,000-node CPU cluster behind the famous Google Brain project, on which Baidu Chief Scientist Andrew Ng worked.</p>

					<p><h4>TWITTER RESEARCH</h4> </p>
                    <p><a href="http://www.forbes.com/sites/kathleenchaykowski/2015/06/18/twitter-acquires-artificial-intelligence-startup-whetlab-in-machine-learning-push/"><h5> Twitter Acquires Artificial Intelligence Startup Whetlab In Machine Learning Push </h5></a></p>
					<p>While acquisitions like this one bring in talent and underlying technology, Twitter should make sure to use its time and energy to focus on improving its user experience and retention,” Jan Rezab, CEO of social media analytics firm Socialbakers, said. “Twitter would do well to create experiences for things like sports, TV, real-time events and to connect these experiences through its central Twitter app.”</p>
					<nav>
            		<ul class="pager">
              		<li><a href="1.html">Previous</a></li>
              		<li><a href="3.html">Next</a></li>
            		</ul>
          			</nav>
										
                </div>
            </div>
        </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="https://twitter.com/DeepSrivignessh">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="https://www.facebook.com/pages/Deep-Learning-Artificial-Intelligence/472081616289751">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/DeepLearningIndia">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <p class="copyright text-muted">Copyright &copy; Newtron.in 2015</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>

</body>

</html>
